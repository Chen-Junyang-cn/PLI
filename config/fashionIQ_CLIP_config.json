{
    "clip_image_model": "ViT-B/32",
    "clip_text_model": "ViT-B/32",
    "dataset": "fashionIQ",
    "evaluator_code": "blip2_evaluator",
    "blip_model_name": "None",
    "blip_model_type": "None",
    "image_encoders": "clip_image_encoder",
    "text_encoders": "clip_text_encoder"
}